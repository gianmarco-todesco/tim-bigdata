{"paragraphs":[{"text":"%md\n# DataFrame, Dataset e RDD #\nIn questa nota studiamo le differenze e le relazioni fra DataFrame, Dataset e RDD.","user":"anonymous","dateUpdated":"2019-04-07T04:20:54-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>DataFrame, Dataset e RDD</h1>\n<p>In questa nota studiamo le differenze e le relazioni fra DataFrame, Dataset e RDD.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1554635949837_-146158007","id":"20190407-041909_797602301","dateCreated":"2019-04-07T04:19:09-0700","dateStarted":"2019-04-07T04:20:54-0700","dateFinished":"2019-04-07T04:20:57-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:321"},{"text":"val ds = spark.range(10,101,10)\nds.show()","user":"anonymous","dateUpdated":"2019-04-07T04:22:13-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---+\n| id|\n+---+\n| 10|\n| 20|\n| 30|\n| 40|\n| 50|\n| 60|\n| 70|\n| 80|\n| 90|\n|100|\n+---+\n\nds: org.apache.spark.sql.Dataset[Long] = [id: bigint]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://quickstart.cloudera:4040/jobs/job?id=55","http://quickstart.cloudera:4040/jobs/job?id=56"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1554636050300_-124192820","id":"20190407-042050_147674441","dateCreated":"2019-04-07T04:20:50-0700","dateStarted":"2019-04-07T04:22:13-0700","dateFinished":"2019-04-07T04:22:13-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:322"},{"text":"// ds è un Dataset di Long che posso manipolare con funzioni Scala\nds.map(x=>x*2+5).show()\nds.first()+1","user":"anonymous","dateUpdated":"2019-04-07T04:33:40-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----+\n|value|\n+-----+\n|   25|\n|   45|\n|   65|\n|   85|\n|  105|\n|  125|\n|  145|\n|  165|\n|  185|\n|  205|\n+-----+\n\nres45: Long = 11\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://quickstart.cloudera:4040/jobs/job?id=64","http://quickstart.cloudera:4040/jobs/job?id=65","http://quickstart.cloudera:4040/jobs/job?id=66"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1554636110324_997904517","id":"20190407-042150_1432100707","dateCreated":"2019-04-07T04:21:50-0700","dateStarted":"2019-04-07T04:33:40-0700","dateFinished":"2019-04-07T04:33:41-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:323"},{"text":"val df = ds.toDF(\"x\")\ndf.show()\ndf.printSchema","user":"anonymous","dateUpdated":"2019-04-07T04:39:53-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---+\n|  x|\n+---+\n| 10|\n| 20|\n| 30|\n| 40|\n| 50|\n| 60|\n| 70|\n| 80|\n| 90|\n|100|\n+---+\n\nroot\n |-- x: long (nullable = false)\n\ndf: org.apache.spark.sql.DataFrame = [x: bigint]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://quickstart.cloudera:4040/jobs/job?id=82","http://quickstart.cloudera:4040/jobs/job?id=83"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1554636268051_-80538074","id":"20190407-042428_909977632","dateCreated":"2019-04-07T04:24:28-0700","dateStarted":"2019-04-07T04:39:53-0700","dateFinished":"2019-04-07T04:39:53-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:324"},{"text":"// df è un DataFrame. Il suo primo elemento è di tipo Row e non può essere direttamente usato in un'espressione aritmetica\nprintln(df.first())\nprintln(df.first.getLong(0)+1)\nprintln(df.first.getAs[Long](0)+1)","user":"anonymous","dateUpdated":"2019-04-07T05:08:15-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[10]\n11\n11\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://quickstart.cloudera:4040/jobs/job?id=105","http://quickstart.cloudera:4040/jobs/job?id=106","http://quickstart.cloudera:4040/jobs/job?id=107"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1554636353510_742054579","id":"20190407-042553_495957257","dateCreated":"2019-04-07T04:25:53-0700","dateStarted":"2019-04-07T05:08:15-0700","dateFinished":"2019-04-07T05:08:15-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:325"},{"text":"%md\nLa documentazione sul tipo Row è in http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Row","user":"anonymous","dateUpdated":"2019-04-07T04:41:30-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>La documentazione sul tipo Row è in <a href=\"http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Row\">http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Row</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1554636771144_-2069027321","id":"20190407-043251_1078059374","dateCreated":"2019-04-07T04:32:51-0700","dateStarted":"2019-04-07T04:41:30-0700","dateFinished":"2019-04-07T04:41:30-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:326"},{"text":"// si può tornare indietro con \ndf.as[Long]\n// e ad es.:\ndf.as[Long].first()+1","user":"anonymous","dateUpdated":"2019-04-07T04:43:00-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res61: Long = 11\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://quickstart.cloudera:4040/jobs/job?id=87"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1554637289982_-73436864","id":"20190407-044129_345167276","dateCreated":"2019-04-07T04:41:29-0700","dateStarted":"2019-04-07T04:43:00-0700","dateFinished":"2019-04-07T04:43:01-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:327"},{"text":"// sia i DataFrame che i Dataset hanno un RDD interno:\nprintln(df.rdd)\nprintln(ds.rdd)","user":"anonymous","dateUpdated":"2019-04-07T04:44:22-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"MapPartitionsRDD[378] at rdd at <console>:31\nMapPartitionsRDD[383] at rdd at <console>:34\n"}]},"apps":[],"jobName":"paragraph_1554637325274_1577500141","id":"20190407-044205_243960446","dateCreated":"2019-04-07T04:42:05-0700","dateStarted":"2019-04-07T04:44:22-0700","dateFinished":"2019-04-07T04:44:22-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:328"},{"text":"// per creare un rdd:\nval rdd = spark.sparkContext.parallelize(1 to 1000)","user":"anonymous","dateUpdated":"2019-04-07T04:45:12-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"rdd: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[384] at parallelize at <console>:27\n"}]},"apps":[],"jobName":"paragraph_1554637446285_-539450014","id":"20190407-044406_350743409","dateCreated":"2019-04-07T04:44:06-0700","dateStarted":"2019-04-07T04:45:12-0700","dateFinished":"2019-04-07T04:45:12-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:329"},{"text":"// che può essere poi trasformato in un DataFrame o in un Dataset:\nrdd.toDF(\"x\")","user":"anonymous","dateUpdated":"2019-04-07T04:45:50-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res64: org.apache.spark.sql.DataFrame = [x: int]\n"}]},"apps":[],"jobName":"paragraph_1554637512232_480422498","id":"20190407-044512_471309296","dateCreated":"2019-04-07T04:45:12-0700","dateStarted":"2019-04-07T04:45:50-0700","dateFinished":"2019-04-07T04:45:50-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:330"},{"text":"// Posso creare un RDD composto di ennuple\nval rdd2 = spark.sparkContext.parallelize(Seq(\n        (\"rosso\",1),\n        (\"verde\",2),\n        (\"blu\",3)\n    ))","user":"anonymous","dateUpdated":"2019-04-07T04:47:48-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"rdd2: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[385] at parallelize at <console>:27\n"}]},"apps":[],"jobName":"paragraph_1554637550497_-1696037714","id":"20190407-044550_1599013353","dateCreated":"2019-04-07T04:45:50-0700","dateStarted":"2019-04-07T04:47:49-0700","dateFinished":"2019-04-07T04:47:49-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:331"},{"text":"// e convertirlo in un dataframe:\nval df2 = rdd2.toDF(\"colore\", \"codice\")\ndf2.show()","user":"anonymous","dateUpdated":"2019-04-07T04:51:41-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------+------+\n|colore|codice|\n+------+------+\n| rosso|     1|\n| verde|     2|\n|   blu|     3|\n+------+------+\n\ndf2: org.apache.spark.sql.DataFrame = [colore: string, codice: int]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://quickstart.cloudera:4040/jobs/job?id=92","http://quickstart.cloudera:4040/jobs/job?id=93"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1554637648699_535666674","id":"20190407-044728_2618487","dateCreated":"2019-04-07T04:47:28-0700","dateStarted":"2019-04-07T04:51:41-0700","dateFinished":"2019-04-07T04:51:42-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:332"},{"text":"// per passare ad un Dataset ho bisogno di definire una classe e un encoder\nimport org.apache.spark.sql.types._\nimport spark.implicits._\ncase class ColoreConCodice(colore:String, codice:Int)\n\nval encoder = org.apache.spark.sql.Encoders.product[ColoreConCodice]\n\nval ds2 = df2.as(encoder)\n\nds2.show()","user":"anonymous","dateUpdated":"2019-04-07T04:59:57-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------+------+\n|colore|codice|\n+------+------+\n| rosso|     1|\n| verde|     2|\n|   blu|     3|\n+------+------+\n\nimport org.apache.spark.sql.types._\nimport spark.implicits._\ndefined class ColoreConCodice\nencoder: org.apache.spark.sql.Encoder[ColoreConCodice] = class[colore[0]: string, codice[0]: int]\nds2: org.apache.spark.sql.Dataset[ColoreConCodice] = [colore: string, codice: int]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://quickstart.cloudera:4040/jobs/job?id=95","http://quickstart.cloudera:4040/jobs/job?id=96"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1554637697731_-1903814381","id":"20190407-044817_179941473","dateCreated":"2019-04-07T04:48:17-0700","dateStarted":"2019-04-07T04:59:57-0700","dateFinished":"2019-04-07T04:59:59-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:333"},{"text":"println(ds2.first.colore)\nprintln(ds2.first.codice * 10 + 1)\n","user":"anonymous","dateUpdated":"2019-04-07T05:00:36-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"rosso\n11\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://quickstart.cloudera:4040/jobs/job?id=101","http://quickstart.cloudera:4040/jobs/job?id=102","http://quickstart.cloudera:4040/jobs/job?id=103","http://quickstart.cloudera:4040/jobs/job?id=104"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1554637854909_178430544","id":"20190407-045054_1484455788","dateCreated":"2019-04-07T04:50:54-0700","dateStarted":"2019-04-07T05:00:36-0700","dateFinished":"2019-04-07T05:00:36-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:334"},{"text":"// In produzione non si usa toDF. E' meglio specificare esplicitamente lo schema\nimport org.apache.spark.sql.Row\nval mioSchema = StructType(Seq(\n    StructField(\"colore\", StringType, true),\n    StructField(\"codice\", IntegerType, true)))\nval dati = Seq(\n    Row(\"rosso\", 1),\n    Row(\"verde\", 2),\n    Row(\"blu\", 3))\nval df3 = spark.createDataFrame(spark.sparkContext.parallelize(dati), mioSchema)\ndf3.show()","user":"anonymous","dateUpdated":"2019-04-07T05:08:56-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------+------+\n|colore|codice|\n+------+------+\n| rosso|     1|\n| verde|     2|\n|   blu|     3|\n+------+------+\n\nimport org.apache.spark.sql.Row\nmioSchema: org.apache.spark.sql.types.StructType = StructType(StructField(colore,StringType,true), StructField(codice,IntegerType,true))\ndati: Seq[org.apache.spark.sql.Row] = List([rosso,1], [verde,2], [blu,3])\ndf3: org.apache.spark.sql.DataFrame = [colore: string, codice: int]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://quickstart.cloudera:4040/jobs/job?id=109","http://quickstart.cloudera:4040/jobs/job?id=110"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1554638405274_13326769","id":"20190407-050005_1077929959","dateCreated":"2019-04-07T05:00:05-0700","dateStarted":"2019-04-07T05:08:56-0700","dateFinished":"2019-04-07T05:08:57-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:335"},{"text":"// in questo caso non ho bisogno di un encoder:\nval ds3 = df3.as[ColoreConCodice]\nprintln(ds3.first.colore)","user":"anonymous","dateUpdated":"2019-04-07T05:09:54-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"rosso\nds3: org.apache.spark.sql.Dataset[ColoreConCodice] = [colore: string, codice: int]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://quickstart.cloudera:4040/jobs/job?id=111","http://quickstart.cloudera:4040/jobs/job?id=112"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1554638576425_1983313860","id":"20190407-050256_1952683598","dateCreated":"2019-04-07T05:02:56-0700","dateStarted":"2019-04-07T05:09:54-0700","dateFinished":"2019-04-07T05:09:54-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:336"},{"text":"%md\n## Esercizio ##\nCreate (con toDF) un dataframe che contenga tre colonne di tipo diverso e visualizzate il contenuto\n","user":"anonymous","dateUpdated":"2019-04-07T05:11:53-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Esercizio</h2>\n<p>Create (con toDF) un dataframe che contenga tre colonne di tipo diverso e visualizzate il contenuto</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1554638910878_600809147","id":"20190407-050830_292696177","dateCreated":"2019-04-07T05:08:30-0700","dateStarted":"2019-04-07T05:11:53-0700","dateFinished":"2019-04-07T05:11:53-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:337"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554647557640_2091010117","id":"20190407-073237_1237261659","dateCreated":"2019-04-07T07:32:37-0700","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:338"}],"name":"/Spark/Lab3/Es1","id":"2E81PP3HF","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}